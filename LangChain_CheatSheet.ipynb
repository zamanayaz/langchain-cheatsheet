{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "7hZ-KGwIk1or",
        "j7iAHgMTl0X1",
        "qVZ_EhGmoswA",
        "bHR3fP9wovi4",
        "JRbEU40NpE7B",
        "ICJrqAQkpjxd",
        "IVNv-DABrkIu",
        "bFBNmvxSsR9w",
        "UD3Ni74YuIkO",
        "SR0tHP7EuLES",
        "7L-X-QdCxGyy",
        "dsEgJ8fgxafW",
        "8NLwM4oaye95",
        "T7sAlzY5zBUD",
        "PZXsoyfmzumB",
        "mLEdP0sXzxND",
        "IesK6IoI0HSz",
        "78qdUiaw0bBt",
        "ut0qdxFj0_o7",
        "JEAgjv7u1-7w",
        "J8Drctw273ig",
        "aHv5793Y26ps",
        "9GTGPBkQ8MXO",
        "6mPJh8brZMKM",
        "l4ELeZozdSv3",
        "SR-BD_UvAQ8N",
        "cHDww7_tEnqR",
        "BbOg_5HiPctv"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Table of Contents\n",
        " 1. Installation & Setup\n",
        " 2. Core Agent Components\n",
        " 3. Agent Types\n",
        " 4. Tools & Toolkits\n",
        " 5. Memory Systems\n",
        " 6. Prompt Engineering  for Agents\n",
        " 7. Agent Execution Patterns\n",
        " 8. Multi-Agent Systems\n",
        " 9. Advance Patterns\n",
        " 10. Debugging & Monitoring\n",
        " 11. Production Considerations\n",
        "\n"
      ],
      "metadata": {
        "id": "m6q5alpOjI0g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installation & Setup"
      ],
      "metadata": {
        "id": "7hZ-KGwIk1or"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Core installation\n",
        "!pip install langchain langchain-openai langchain-community\n",
        "\n",
        "# Additional packages for specific tools\n",
        "pip install langchain-experimental\n",
        "pip install duckduckgo-search\n",
        "pip install wikipedia\n",
        "pip install requests beautifulsoup4\n",
        "pip install pandas numpy\n",
        "pip install python-dotenv\n",
        "\n",
        "#Basic Setup\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "from langchain_openai imoprt ChatOpenAI\n",
        "from langchain.agents import initialize_agent, AgentType\n",
        "\n",
        "load_dotenv()\n",
        "llm = ChatOpenAI(temperature=0, model=\"gpt-5\")"
      ],
      "metadata": {
        "id": "Qc_LXVKgk5Oh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Core Agent Components"
      ],
      "metadata": {
        "id": "j7iAHgMTl0X1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Language Model (LLM)"
      ],
      "metadata": {
        "id": "Eqnj_G1bl3O3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_anthropic import ChatAnthropic\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "# OpenAI\n",
        "llm = ChatOpenAI(\n",
        "    model=\"gpt-5\",\n",
        "    temperature=0,\n",
        "    max_tokens=1000,\n",
        ")\n",
        "\n",
        "# Anthropic Claude\n",
        "llm = ChatAnthropic(\n",
        "    model = \"claude-3-sonnet-20240229\"\n",
        "    temperature=0\n",
        ")\n",
        "\n",
        "# Google Gemini\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-pro\",\n",
        "    temperature=0\n",
        ")"
      ],
      "metadata": {
        "id": "72FafxKvmJTF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Tools"
      ],
      "metadata": {
        "id": "78r_Ear8m5gL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.tools import Tool\n",
        "from langchain_community.tools import DuckDuckGoSearchRun\n",
        "from langchain_community.tools import WikipediaQueryRun\n",
        "from langchain_community.utilities import WikipediaAPIWrapper\n",
        "\n",
        "# Simple function-based tool\n",
        "def calculator(expression: str) -> str:\n",
        "  \"\"\" Calculate mathematical expressions\"\"\"\n",
        "  try:\n",
        "    return str(evel(expression))\n",
        "  except:\n",
        "    return \"Invalid Expression\"\n",
        "\n",
        "calculator_tool = Tool(\n",
        "    name = \"Calculator\",\n",
        "    func=\"calculator\",\n",
        "    description = \"Useful for mathematical calculations. Input should be valid mathematical expression.\"\n",
        ")\n",
        "\n",
        "# Pre-built tools\n",
        "search = DuckDuckGoSearchRun()\n",
        "wikipedia=WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper())\n",
        "\n",
        "tools = [calculator_tool, searcch, wikipedia]"
      ],
      "metadata": {
        "id": "B29jXpIzm-Ft"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Agent Initialziation"
      ],
      "metadata": {
        "id": "FniGDkO3oG0c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import initialize_agent, AgentType\n",
        "\n",
        "agent = initialize_agent(\n",
        "    tools = tools,\n",
        "    llm = llm,\n",
        "    agent = AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    verbose = True,\n",
        "    max_iterations=3,\n",
        "    early_stopping_method = \"generate\",\n",
        ")"
      ],
      "metadata": {
        "id": "XUJJPqRaoOGA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Agent Types"
      ],
      "metadata": {
        "id": "qVZ_EhGmoswA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Zero-Shot ReAct Agent\n"
      ],
      "metadata": {
        "id": "bHR3fP9wovi4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import initialize_agent, AgentType\n",
        "\n",
        "agent = initialize_agent(\n",
        "    tools = tools,\n",
        "    llm = llm,\n",
        "    agent = AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    verbose = True,\n",
        "    max_iterations=3,\n",
        "    early_stopping_method = \"generate\",\n",
        ")\n",
        "\n",
        "#Usage\n",
        "result = agent.run(\"What's the weather in Bahawalpur.\")"
      ],
      "metadata": {
        "id": "BEs87_3Vo1OJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Conversational ReAct Agent"
      ],
      "metadata": {
        "id": "JRbEU40NpE7B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import initialize_agent, AgentType\n",
        "from langchain.memory improt ConversationBufferMemory\n",
        "memory = ConversationBufferMemory(memory_key=\"chat_history\")\n",
        "\n",
        "agent = initialize_agent(\n",
        "    tools = tools,\n",
        "    llm = llm,\n",
        "    agent = AgentType.CONVERSATIONS_REACT_DESCRIPTION,\n",
        "    memory = memory,\n",
        "    verbose = True,\n",
        ")"
      ],
      "metadata": {
        "id": "NP3UyWQipIUZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Structured Tool Chat Agent\n"
      ],
      "metadata": {
        "id": "ICJrqAQkpjxd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import initialize_agent, AgentType\n",
        "\n",
        "agent = initialize_agent(\n",
        "    tools = tools,\n",
        "    llm = llm,\n",
        "    agent = AgentType.STRUCTURE_CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    verbose = True,\n",
        ")"
      ],
      "metadata": {
        "id": "R7Q9WKK5polP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. OpenAI Functions Agent"
      ],
      "metadata": {
        "id": "IVNv-DABrkIu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import initialze_agent, AgentType\n",
        "\n",
        "agent = initialize_agent(\n",
        "    tools = tools,\n",
        "    llm = llm,\n",
        "    agent= AgentType.OPENAI_FUNCTIONS,\n",
        "    verbose = True,\n",
        ")"
      ],
      "metadata": {
        "id": "ELtTcC8gr67C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Custom Agnet with LangGraph"
      ],
      "metadata": {
        "id": "bFBNmvxSsR9w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import StateGraph, END\n",
        "from typing import TypedDict, List\n",
        "\n",
        "class AgentState(TypedDict):\n",
        "  messages: List[str]\n",
        "  next_action: str\n",
        "\n",
        "def should_continue(state):\n",
        "  return \"continue\" if len(state([\"messages\"])) < 5 else \"end\"\n",
        "\n",
        "def call_model(state):\n",
        "  # Your model calling logic\n",
        "  response = llm.invoke(state[\"messages\"][-1])\n",
        "  return {\"messages\":state[\"messages\"] + [response.content]}\n",
        "\n",
        "workflow = StateGraph(AgentState)\n",
        "workflow.add_node(\"agent\", call_model)\n",
        "workflow.add_conditional_edges(\"agent\", should_continue, {\n",
        "    \"continue\": \"agent\",\n",
        "    \"end\": END\n",
        "})\n",
        "workflow.set_entry_point(\"Agent\")\n",
        "\n",
        "app = workflow.compile()\n"
      ],
      "metadata": {
        "id": "z5_GIpjvsmmh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tools and Toolkits"
      ],
      "metadata": {
        "id": "UD3Ni74YuIkO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Custom Tools"
      ],
      "metadata": {
        "id": "SR0tHP7EuLES"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.tools import BaseTool\n",
        "from typing import Optional\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "class CalculatorInput(BaseModel):\n",
        "  expression: str = Field(description=\"Mathematical expression to evaluate.\")\n",
        "\n",
        "class CalculatorTool(BaseTool):\n",
        "  name = \"calculator\"\n",
        "  description=\"useful for mathematical calculations\"\n",
        "  args_schema = CalculatorInput\n",
        "\n",
        "  def _run(self, expression: str) -> str:\n",
        "    try:\n",
        "      return str(eval(expression))\n",
        "    except Exception as e:\n",
        "      return f\"Error: {str(e)}\"\n",
        "  async def _arun(self, expression: str) -> str:\n",
        "    return self._run(expression)\n",
        "\n",
        "calculator = CalculatorTool()"
      ],
      "metadata": {
        "id": "8ILSra6ouO63"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. File System Tools\n"
      ],
      "metadata": {
        "id": "7L-X-QdCxGyy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.tools import ReadFileTool, WriteFileTool\n",
        "read_tool = ReadFileTool()\n",
        "write_tool = WriteFileTool()\n",
        "\n",
        "tools = [read_tool, write_tool]"
      ],
      "metadata": {
        "id": "VGN4PAfIxJFq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Web Scraping Tools"
      ],
      "metadata": {
        "id": "dsEgJ8fgxafW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from langchain.tools import Tool\n",
        "\n",
        "def scrape_website(url: str) -> str:\n",
        "  \"\"\"Scrape content from a webiste\"\"\"\n",
        "  try:\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "    return soup.get_text()[:5000]\n",
        "  except Exception as e:\n",
        "    return f\"Error scraping {url}: {str{e}}\"\n",
        "\n",
        "scraper_tool = Tool(\n",
        "    name=\"WebScraper\",\n",
        "    func=scrape_website,\n",
        "    description=\"Scrape content from websites. Input should be valid URL.\"\n",
        ")"
      ],
      "metadata": {
        "id": "08cUJEWxxc-u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Database Tools"
      ],
      "metadata": {
        "id": "8NLwM4oaye95"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.tools.sql_database.tool import QuerySQLDataBaseTool\n",
        "from langchain_community.utilities import SQLDatabase\n",
        "\n",
        "# SQLite\n",
        "db = SQLDatabase.from_url(\"sqlite://example.db\")\n",
        "db_tool = QuerySQLDataBaseTool(db=db)\n",
        "\n",
        "tools = [db_tool]"
      ],
      "metadata": {
        "id": "2NR04xytyirW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. API Tools"
      ],
      "metadata": {
        "id": "T7sAlzY5zBUD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from langchain.tools import Tool\n",
        "def call_api(endpoint: str) -> str:\n",
        "  \"\"\"Make API calls to external services.\"\"\"\n",
        "  try:\n",
        "    response = requests.get(endpoint)\n",
        "    return response.json()\n",
        "  except Exception as e:\n",
        "    return f\"API Error: {str(e)}\"\n",
        "\n",
        "  api_tool = Tool(\n",
        "      name=\"APITool\",\n",
        "      func = call_api,\n",
        "      description = \"Make API calls. Input should be a valid API endpoint.\"\n",
        "  )"
      ],
      "metadata": {
        "id": "qmLmAOh2zDnF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Memory Systems"
      ],
      "metadata": {
        "id": "PZXsoyfmzumB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Conversation Buffer Memory\n"
      ],
      "metadata": {
        "id": "mLEdP0sXzxND"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.memory import ConversationBufferMemory\n",
        "\n",
        "memory = ConversationBufferMemory(\n",
        "    memory_key = \"chat_history\",\n",
        "    return_messages = True\n",
        ")"
      ],
      "metadata": {
        "id": "osqd0VqXz2y5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Conversation Buffer Window Memory"
      ],
      "metadata": {
        "id": "IesK6IoI0HSz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.memory import ConversationBufferWindowMemory\n",
        "\n",
        "memory = ConversationBufferWindowMemory(\n",
        "    k = 5,\n",
        "    memory_key = \"chat_history\",\n",
        "    return_messages = True,\n",
        ")"
      ],
      "metadata": {
        "id": "Q-y5Df8b0NM2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Conversation Summary Memory"
      ],
      "metadata": {
        "id": "78qdUiaw0bBt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.memory import ConversationSummaryMemory\n",
        "\n",
        "memory = ConversationSummaryMemory(\n",
        "    llm = llm,\n",
        "    memory_key = \"chat_history\",\n",
        "    return_messages = True,\n",
        ")"
      ],
      "metadata": {
        "id": "im3LkRUa0t8H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Vector Store Memory"
      ],
      "metadata": {
        "id": "ut0qdxFj0_o7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.memory import VectorStoreRetrieverMemory\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "embeddings = OpenAIEmbeddings()\n",
        "vectorstore = FAISS.from_texts([\"\"], embeddings)\n",
        "retriever = vectorstore.as_retriever(search_kwargs=dict(k=1))\n",
        "\n",
        "memory = VectorStoreRetrieverMemory(\n",
        "    retriever = retriever,\n",
        "    memory_key = \"chat_history\",\n",
        ")"
      ],
      "metadata": {
        "id": "CpadaE-G1B-X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Custom Memory\n",
        "\n"
      ],
      "metadata": {
        "id": "JEAgjv7u1-7w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.memory.chat_memory import BaseChatMemory\n",
        "from langchain.schema import BaseMessage\n",
        "\n",
        "class CustomMemory(BaseChatMemory):\n",
        "  def __init__(self):\n",
        "    super().__init__(return_messages=True)\n",
        "    self.storage = []\n",
        "\n",
        "  def save_context(self, inputs, outputs):\n",
        "    # Custom save logic\n",
        "    self.storage.append({\"input\":inputs, \"output\":outputs})\n",
        "\n",
        "  def clear(self):\n",
        "    self.storage = []"
      ],
      "metadata": {
        "id": "G91NEp4l2Bsy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prompt Engineerig for Agents"
      ],
      "metadata": {
        "id": "J8Drctw273ig"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Custom Agent Prompts\n"
      ],
      "metadata": {
        "id": "aHv5793Y26ps"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import ZeroShotAgent\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "template = \"\"\"\n",
        "\n",
        "You are a helpful AI assistant with access to the following tool:\n",
        "{tools}\n",
        "\n",
        "Use the following format:\n",
        "\n",
        "Question: the input question you must answer.\n",
        "Thought: You should always think about what to do.\n",
        "Action: The action to take, should be none of [{tool_names}]\n",
        "Action Input: the input to the action\n",
        "Observation: the result of the action\n",
        "...(this Thought/Action/Action Input/Observation can repeat  N times)\n",
        "Thought: I now know the final answer\n",
        "Final Answer: the final answer to the original input question\n",
        "\n",
        "Begin!\n",
        "\n",
        "Question: {input}\n",
        "{agent_scratchpage}\n",
        "\"\"\"\n",
        "\n",
        "prompt = ZeroShotAgent.create_prompt(\n",
        "    tools = tools,\n",
        "    prefix = \"You are a helpful AI Assistant.\",\n",
        "    suffix=\"Begin!\\n\\nQuestion: {input}\\n{agent_scratchpage}\",\n",
        "    input_variables = [\"input\",\"agent_scratchpage\"],\n",
        ")\n",
        "\n",
        "agent = ZeroShotAgent(\n",
        "    llm_chain = llm,\n",
        "    tools = tools,\n",
        "    prompt = prompt\n",
        ")\n"
      ],
      "metadata": {
        "id": "3mjKaXyB3Fn3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. System Message Customization\n"
      ],
      "metadata": {
        "id": "YiXvPCjS4_Dy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import AgentType, initialze_agent\n",
        "from langchian.memory import ConversationBufferMemory\n",
        "\n",
        "system_message = \"\"\"\n",
        "You are an expert data analyst AI assistant. You have access to the various tools to help analyze data, search for information, and perform calculations.\n",
        "\n",
        "Always:\n",
        "1. Think step by step\n",
        "2. Verify your calculations\n",
        "3. Provide clear explanations\n",
        "4. Ask for clarification if the request is ambiguous\n",
        "\n",
        "When working with data:\n",
        "- Always examine data structure first\n",
        "- Handle missing values appropriately\n",
        "- Provide visualizations when helpful\n",
        "\"\"\"\n",
        "\n",
        "agent = initialize_agent(\n",
        "    tools = tools,\n",
        "    llm = llm,\n",
        "    agent = AgnetType.CONVERSATIONAL_REACT_DESCRIPTION,\n",
        "    verbose = True,\n",
        "    memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True),\n",
        "    agent_kwargs= {\n",
        "        \"system_message\": system_message\n",
        "    }\n",
        "\n",
        ")"
      ],
      "metadata": {
        "id": "XnfPRgUc5HAY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Agent Execution Patterns"
      ],
      "metadata": {
        "id": "OPzF5hEQ8KOF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Basic Agent Execution"
      ],
      "metadata": {
        "id": "9GTGPBkQ8MXO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple Run\n",
        "result = agent.run(\"What's 25*4 +10?\")\n",
        "\n",
        "# Run with Input\n",
        "result = agent({\"input\": \"Search for recent news about AI.\"})\n",
        "\n",
        "# Async execution\n",
        "import asyncio\n",
        "\n",
        "async def run_agent():\n",
        "  result = await agent.run(\"What's weather in Bahwalpur?\")\n",
        "  return result\n",
        "result = asyncio.run(run_agent())"
      ],
      "metadata": {
        "id": "3ySlWw6D8QUd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Streaming Agent Responses"
      ],
      "metadata": {
        "id": "5ob_Lt2J8z2X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
        "\n",
        "agent = initialize_agent(\n",
        "    tools = tools,\n",
        "    llm = llm,\n",
        "    agent = AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    verbose = True,\n",
        "    callbacks = [StreamingStdOutCallbackHandler()]\n",
        ")"
      ],
      "metadata": {
        "id": "T3M0bAPX82lx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Agent with Error Handling"
      ],
      "metadata": {
        "id": "MNaO_L1T9fhh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def safe_agent_run(agent, query, max_retries=3):\n",
        "  for attempt in range(max_retries):\n",
        "    try:\n",
        "      result agent.run(query)\n",
        "      return result\n",
        "    exception Exception as e:\n",
        "      print(f\"Attempt {attempt + 1} failed: {ste(e)}\")\n",
        "      if attempt == max_retries-1:\n",
        "        return f\"Agent failed after{max_retries} attempts: {str(e)}\"\n",
        "\n",
        "result = sage_agent_run(agent, \"Complex query here\")"
      ],
      "metadata": {
        "id": "U-06spaa9jn9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Agent with Timeout"
      ],
      "metadata": {
        "id": "fHSy5qRV-OLn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import signal\n",
        "from contextlib import contextmanager\n",
        "\n",
        "@contextmanager\n",
        "def timeout(duration):\n",
        "  def timeout_handler(signum, frame):\n",
        "    raise TimeoutError(f\"Timed out after {duration} seconds\")\n",
        "\n",
        "  signal.signal(signal.SIGALRM, timeout_handler)\n",
        "  signal.alarm(duration)\n",
        "  try:\n",
        "    yield\n",
        "  finally:\n",
        "    signal.alarm(0)\n",
        "\n",
        "try:\n",
        "  with timeout(30):\n",
        "    result = agent.run(\"Long running query\")\n",
        "  except TimeoutError:\n",
        "    result \"Agent Execution timedout.\""
      ],
      "metadata": {
        "id": "hvf4WgDs-NaP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multi-Agent Systems"
      ],
      "metadata": {
        "id": "6mPJh8brZMKM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sequential Agent Chain"
      ],
      "metadata": {
        "id": "xxE1sZR0ZS2b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import initialize_agent, AgentType\n",
        "from langchain.schema import HumanMessage\n",
        "\n",
        "# Create specialized agents\n",
        "researcher = initialize_agent(\n",
        "    tools = [search, wikipedia],\n",
        "    llm = llm,\n",
        "    agent = AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "analyst = initialize_agent(\n",
        "    tools = [calculator_tool],\n",
        "    llm = llm,\n",
        "    agent = AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "# Sequential Execution\n",
        "def multi_agent_workflow(query):\n",
        "  # Step 1 : Research\n",
        "  research_result = researcher.run(f\"Research information about: {query}\")\n",
        "\n",
        "  # Step 2 : Analysis\n",
        "  anaylysis_result = analyst.run(f\"Analyze this information: {research result}\")\n",
        "\n",
        "  return {\"research\":research_result, \"analysis\":analysis_result}\n",
        "\n",
        "result = multi_agent_workflow(\"Tesla's quarterly earnings.\")"
      ],
      "metadata": {
        "id": "faM4VXViZW3n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Parallel Agent Execution"
      ],
      "metadata": {
        "id": "W0aQzSysbPMb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "\n",
        "async def parallel_agents(quries):\n",
        "  with ThreadPoolExecutor() as executor:\n",
        "    loop = asyncio.get_event_loop()\n",
        "    tasks = [\n",
        "        loop.run_in_executor(executor, agent.run, query)\n",
        "    ]\n",
        "    results = await asyncio.gather(*tasks)\n",
        "  return results\n",
        "\n",
        "queries = [\n",
        "    \"What's weather in Bahawalpur?\",\n",
        "    \"Calculate 15 * 23 + 45\",\n",
        "    \"Search for recent AI news\"\n",
        "]\n",
        "\n",
        "results = asyncio.run(parallel_agents(queries))"
      ],
      "metadata": {
        "id": "OLGGBXSbbSRM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Agent Conversation"
      ],
      "metadata": {
        "id": "7mLNN9EAcG_X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AgentConversation:\n",
        "  def __init__(self, agents):\n",
        "    self.agents = agents\n",
        "    self.conversation_history = []\n",
        "\n",
        "  def run_conversation(self, initial_message, max_turns=5):\n",
        "    current_message = initial_message\n",
        "    current_agent_idx = 0\n",
        "\n",
        "    for turn in range(max_turns):\n",
        "      agent = self.agents[current_agent_idx]\n",
        "      response = agent.run(current_message)\n",
        "\n",
        "      self.conversation_history.append({\n",
        "          \"agent\": current_agent_idx,\n",
        "          \"input\": current_message,\n",
        "          \"output\": response\n",
        "      })\n",
        "\n",
        "      # Switch to next agent\n",
        "      current_agent_idx = (current_agent_idx + 1) % len(self.agents)\n",
        "      current_message = response\n",
        "    return self.conversation_history\n",
        "\n",
        "# Usage\n",
        "conversation = AgentConversation([researcher, analyst])\n",
        "history = conversation.run_conversation(\"Analyze the impact of AI boom on job markets.\")"
      ],
      "metadata": {
        "id": "S2XluovKcJdp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Advanced Patterns\n"
      ],
      "metadata": {
        "id": "l4ELeZozdSv3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Self-Correcting Agent"
      ],
      "metadata": {
        "id": "KouUqlaKdWUX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SelfCorrectingAgent:\n",
        "  def __init__(self, agent, validator_llm):\n",
        "    self.agent = agent\n",
        "    self.validator = validator_llm\n",
        "\n",
        "  def run_with_validation(self, query, max_connections=3):\n",
        "    for attemp in range(max_connections):\n",
        "      result = self.agent.run(query)\n",
        "\n",
        "      # Validate result\n",
        "      validation_prompt = f\"\"\"\n",
        "      Query: {query}\n",
        "      Result: {result}\n",
        "\n",
        "      Is this result accurate and complete? If not, what corrections are needed?\n",
        "      Respond with 'Valid' if correct, or 'Invalid: [explanation]' if incorrect.\n",
        "      \"\"\"\n",
        "\n",
        "      validation = self.validator.invoke(validation_prompt).content\n",
        "\n",
        "      if validation.startswith('Valid'):\n",
        "        return result\n",
        "      else:\n",
        "        # Modify query for correction\n",
        "        query = f\"{query}\\n\\nPrevious attempt: {result}\\nCorrection needed: {validation}\"\n",
        "\n",
        "     return result\n",
        "\n",
        "correcting_agent = SelfCorrectingAgent(agent, llm)\n",
        "result = correcting_agent.run_with_validation(\"Calculate.\")"
      ],
      "metadata": {
        "id": "cAlsevW3darA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Agent with Planning"
      ],
      "metadata": {
        "id": "tPtx87_re18_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import PlanAndExecute\n",
        "from langchain_experimental.plan_and_execute import (PlanAndExecuteAgentExecutor, load_agent_executor, load_chat_planner)\n",
        "\n",
        "planner = load_chat_planner(llm)\n",
        "executor = load_agent_executor(llm, tools, verbose=True)\n",
        "\n",
        "plan_ang_execute_agent = PlanAndExecuteAgentExecutor(\n",
        "    planner = planner,\n",
        "    executor = executor,\n",
        "    verbose = true,\n",
        ")\n",
        "\n",
        "result = plan_and_execute_agent.run(\"Plan a 3-day trip to Paris including budget analysis.\")"
      ],
      "metadata": {
        "id": "5YwVsQBBe39h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Hierarchical Agent System"
      ],
      "metadata": {
        "id": "8MMuK5u2fjQM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class HierarchicalAgent:\n",
        "  def __init__(self, coordinator_agent, specialist_agents):\n",
        "    self.coordinator = coordinator_agent\n",
        "    self.specialists = specialist_agents\n",
        "\n",
        "  def run(self, query):\n",
        "    decision_prompt = f\"\"\"\n",
        "    Query : {query}\n",
        "    Available specialists: {list(self.specialists.keys())}\n",
        "    Which specialist should handle this query? Respond with just the specialist name.\n",
        "    \"\"\"\n",
        "\n",
        "    specialist_choice = self.coordinator.run(decision_prompt)\n",
        "\n",
        "    # Route to appropriate specialist\n",
        "    if specialist_choice in self.specialists:\n",
        "      return self.specialists[specialist-choice].run(query)\n",
        "    else:\n",
        "      return self.coordinator.run(query)\n",
        "\n",
        "# Create hierarchical system\n",
        "specialists = {\n",
        "    \"math\": initialize_agent([calculator_tool], AgentType.ZERO_SHOT_REACT_DESCRIPTION),\n",
        "    \"research\": initialize_agent([search, wikipedia])m llm, AgentType.ZERO_SHOT_REACT_DESCRIPTION),\n",
        "    \"data\": initialze_agent([db_tool], llm, AgentType.ZERO_SHOT_REACT_DESCRIPTION)\n",
        "}\n",
        "\n",
        "hierarchical_system = HierarchicalAgent(agent, specialsists)"
      ],
      "metadata": {
        "id": "nmccsMe5fmH1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Debugging & Monitoring"
      ],
      "metadata": {
        "id": "SR-BD_UvAQ8N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Verbose Logging"
      ],
      "metadata": {
        "id": "aUdXOJuVBFb3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "\n",
        "# Set up logging\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Enable Verbose mode\n",
        "agent = initialize_agent(\n",
        "    tools = tools,\n",
        "    llm = llm,\n",
        "    agent = AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    verbose=True,\n",
        "    return_intermediate_steps=True,\n",
        ")\n",
        "\n",
        "# Run with detailed output\n",
        "result = agent({\"input\": \"What is 2+2\"})\n",
        "print(\"final result\", result[\"output\"])\n",
        "print(\"intermediate steps\", result[\"intermediate_steps\"])"
      ],
      "metadata": {
        "id": "6S6vi51UATvl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Custom Callbacks"
      ],
      "metadata": {
        "id": "njJ_keGsBIqv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.callbacks.base import BaseCallBackHandler\n",
        "from typing import Any, Dict, List\n",
        "\n",
        "class CustomCallbackhandler(BaseCallbackHandler):\n",
        "  def on_agent_action(self, action, **kwargs):\n",
        "    print(f\"Agent is taking action: {action.tool}\")\n",
        "    print(f\"Agent input: {action.tool_input}\")\n",
        "\n",
        "  def on_agent_finish(self, finish, **kwargs):\n",
        "    print(f\"Agent finised with output: {finish.return_values}\")\n",
        "\n",
        "  def on_tool_start(self, serialized: Dict[str, Any], input_str: str, **kwargs):\n",
        "    print(f\"Tool {serialized[\"name\"]} started with input {input_str}\")\n",
        "\n",
        "  def on_tool_end(self, output:str, **kwargs):\n",
        "    print(f\"Tool finished with output: {output}\")\n",
        "\n",
        "# Use custom callback\n",
        "callback_handler = CustomCallbackHandler()\n",
        "agent = initialzie_agent(\n",
        "    tools = tools,\n",
        "    llm = llm,\n",
        "    agent = AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    callbacks=[callback_handler]\n",
        ")"
      ],
      "metadata": {
        "id": "LbKgnmywBMs0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Performance Monitoring"
      ],
      "metadata": {
        "id": "BSY8hiG8CwII"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from functools import wraps\n",
        "\n",
        "def monitor_performance(func):\n",
        "  @wraps(func)\n",
        "  def wrapper(*args, **kwargs):\n",
        "    start_time = time.time()\n",
        "    result = func(*args, **kwargs)\n",
        "    end_time = time.time()\n",
        "\n",
        "    print(f\"Function {func.__name__} took {end_time-start_time:.2f} seconds\")\n",
        "    return result\n",
        "  return wrapper\n",
        "\n",
        "@monitor_performance\n",
        "def run_agent_with_monitoring(query):\n",
        "  return agent.run(query)\n",
        "\n",
        "result = run_agent_with_monitoring(\"Complex query here.\")"
      ],
      "metadata": {
        "id": "FFK_dC3jCyuX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Error Tracking"
      ],
      "metadata": {
        "id": "KDXrBp7sDmYY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ErrorTrackingAgent:\n",
        "  def __init__(self, agent):\n",
        "    self.agent = agent\n",
        "    self.errors = []\n",
        "\n",
        "  def run(self, query):\n",
        "    try:\n",
        "      result = self.agent.run(query)\n",
        "      return result\n",
        "    except Exception as e:\n",
        "      error_info = {\n",
        "          \"query\":query,\n",
        "          \"error\":str(e),\n",
        "          \"timestamp\":time.time()\n",
        "      }\n",
        "      self.errors.append(error_info)\n",
        "      raise e\n",
        "\n",
        "  def get_error_summary(self):\n",
        "    return {\n",
        "        \"total_errors\": len(self.errors),\n",
        "        \"recent_errors\": self.errors[-5:] if self.errors else []\n",
        "    }\n",
        "\n",
        "tracked_agent = ErrorTrackingAgent(agent)"
      ],
      "metadata": {
        "id": "RRejyPX-DpAo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Production Consideration"
      ],
      "metadata": {
        "id": "cHDww7_tEnqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Rate Limiting"
      ],
      "metadata": {
        "id": "kyr9B1tBEp5N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from threading import Lock\n",
        "\n",
        "class RateLimitedAgent:\n",
        "  def __init__(self, agent, calls_per_minute=60):\n",
        "    self.agent = agent\n",
        "    self.calls_per_minute = calls_per_minute\n",
        "    self.calls = []\n",
        "    self.lock = Lock()\n",
        "\n",
        "  def run(self, query):\n",
        "    with self.lock:\n",
        "      now = time.time()\n",
        "      # Remove calls older than 1 minute\n",
        "      self.calls = [call_time for call_time in self.calls if now-call_time<60]\n",
        "\n",
        "      if len(self.calls) >= self.calls_per_minute:\n",
        "        sleep_time = 60 - (now - self.calls(0))\n",
        "        time.sleep(sleep_time)\n",
        "\n",
        "      self.calls.append(now)\n",
        "\n",
        "    return self.agent.run(query)\n",
        "\n",
        "rate_limited_agent = RateLimitedAgent(agent, calls_per_minute)"
      ],
      "metadata": {
        "id": "XtfnLCBoErz_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Caching Results"
      ],
      "metadata": {
        "id": "ltQL-In9FhBm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from functools import lru_cache\n",
        "import hashlib\n",
        "import json\n",
        "\n",
        "class CachedAgent:\n",
        "  def __init__(self, agent, cache_size=128):\n",
        "    self.agent = agent\n",
        "    self.cache = {}\n",
        "    self.cache_size = cache-size\n",
        "\n",
        "  def _get_chache_key(self, query):\n",
        "    return hashlib.md5(query.encode()).hexdigest()\n",
        "\n",
        "  def run(self, query):\n",
        "    cache_key = self._get_cache_key(query)\n",
        "\n",
        "    if cache_key in self.cache:\n",
        "      print(\"cache hit!\")\n",
        "      return self.cache[cache_key]\n",
        "    result = self.agent.run(query)\n",
        "\n",
        "    # Simple LRU cache Implementation\n",
        "    if len(self.cache) >= self.cache-size:\n",
        "      # Remove oldest entry\n",
        "      oldest_key = next(iter(self.cache))\n",
        "      del.self.cache[oldest_key]\n",
        "\n",
        "    self.cache[cache_key] = result\n",
        "    return result\n",
        "\n",
        "cached_agent = CachedAgent(agent)"
      ],
      "metadata": {
        "id": "OFhP4f0fFjGs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Configuration Management"
      ],
      "metadata": {
        "id": "XsqQc5WRGrjt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from dataclasses import dataclass\n",
        "from typing import List, Dict, Any\n",
        "\n",
        "@dataclass\n",
        "class AgentConfig:\n",
        "  model_name: str \"gpt-5\"\n",
        "  temperature: float = 0\n",
        "  max_tokens: int = 1000\n",
        "  max_iterations: int = 3\n",
        "  verbose: bool = True\n",
        "  timeout; int = 30\n",
        "  tools: List[str] = \"buffer\"\n",
        "  memory_size: int = 10\n",
        "\n",
        "def create_agent_from_config(config: AgentConfig):\n",
        "  llm = ChatOpenAI(\n",
        "      model = config.model_name,\n",
        "      temperature= config.temperature,\n",
        "      max_tokens = config.max_tokens,\n",
        "  )\n",
        "\n",
        "  # configure memory based on type\n",
        "  if config.memory_type == \"buffer\":\n",
        "    memory = ConversationBufferMemory(memory_key=\"chat_history\")\n",
        "  elif config.memory_type = \"window\":\n",
        "    memory = ConversationBufferWindowMemory(k=config.memory_size,memory_key=\"chat_history\")\n",
        "  else:\n",
        "    memroy = None\n",
        "\n",
        "  return initialze_agent(\n",
        "      tools = tools,\n",
        "      llm = llm,\n",
        "      agent = AgentType.CONVERSATIONAL_REACT_DESCRIPTION,\n",
        "      memory= memory,\n",
        "      verbose=config.verbose,\n",
        "      max_iterations = config.max_iterations\n",
        "  )\n",
        "\n",
        "# Usage\n",
        "config = AgentConfig(model_name=\"gpt-5\", temperature=0.2)\n",
        "production_agent = create_agent_from_config(config)"
      ],
      "metadata": {
        "id": "0PAI13sEGwUE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Health Checks"
      ],
      "metadata": {
        "id": "Wtdiad3fOJJw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class HealthCheckedAgent:\n",
        "  def __init__(self, agent):\n",
        "    self.agent = agent\n",
        "    self.is_healthy = True\n",
        "    self.last_health_check = time.time()\n",
        "\n",
        "  def health_check(self):\n",
        "    try:\n",
        "      # Simple health check with basic query\n",
        "      result = self.agent.run(\"What is 1+1\")\n",
        "      self.is_healthy = \"2\" in str(result)\n",
        "      self.last_health_check = time.time()\n",
        "      return self.is_healthy\n",
        "    except Exception:\n",
        "      self.is_healthy = False\n",
        "      return False\n",
        "\n",
        "  def run(self, query):\n",
        "    # Check health every 5 minutes\n",
        "    if time.time() - self.last_health_check > 300:\n",
        "      if not self.health_check():\n",
        "        raise Exception(\"Agent Health Check failed.\")\n",
        "    if not self.is_healthy:\n",
        "      raise Exception(\"Agent is not healthy\")\n",
        "    return self.agent.run(query)\n",
        "\n",
        "healthy_agent = HealthCheckedAgent(agent)"
      ],
      "metadata": {
        "id": "4sBQJicaOLdm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Quick Reference"
      ],
      "metadata": {
        "id": "BbOg_5HiPctv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Basic agent setuo\n",
        "from langchain.agents import initialize_agent, AgentType\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_community.tools import DuckDuckGoSearchRun\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-flash\", temperature=\"0\")\n",
        "tools = [DuckDuckGoSearchRun()]\n",
        "agent = initialize_agent(tools, llm, AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)\n",
        "\n",
        "# Run Agent\n",
        "result = agent.run(\"Your query here.\")\n",
        "\n",
        "# With memory\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "memory = ConversationBufferMemory(memory_key=\"chat_history\")\n",
        "agent = initialize_agent(tools, llm, AgentType.CONVERSATIONAL_REACT_DESCRIPTION, memory=memory)\n",
        "\n",
        "# Custom Tool\n",
        "from langchain.tools import Tool\n",
        "def my_function(input_str): return f\"Result: {input_str}\"\n",
        "my_tool = Tool(name=\"MyTool\", func=my_function, description=\"description here\")\n",
        "\n",
        "# Async execution\n",
        "result = await agent.arun(\"Your query here.\")"
      ],
      "metadata": {
        "id": "3URAQBqBPege"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# What can I build with this\n",
        "\n",
        "## >> Research Assistants\n",
        "- Agents that search , analyse, and synthesize the information\n",
        "\n",
        "## >> Data Analysis Bots\n",
        "- Agents that query databases and perform calculations\n",
        "\n",
        "## >> Task Automation\n",
        "- Multi-step workflow agents with planning capabilities\n",
        "\n",
        "## >> Customer Service Bots\n",
        "- Conversational agents with memory and tool access\n",
        "\n",
        "## >> Content Creation\n",
        "- Agents that research , write, and fact-check content\n",
        "\n",
        "## >> Decision Support\n",
        "- Agents that gather data and provide recommendation"
      ],
      "metadata": {
        "id": "dIvybdPsQ_Rx"
      }
    }
  ]
}